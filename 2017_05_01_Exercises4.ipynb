{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on each subset:\n",
      "[ 0.67581047  0.69326683  0.6275      0.62406015  0.64661654]\n",
      "Average score and uncertainty: (65.35 +- 1.211)%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "np.random.seed(6450345)\n",
    "\n",
    "def make_data(N=1000, n_vars=10,\n",
    "              n_classes=2):\n",
    "    X = np.random.normal(size=(N,n_vars))\n",
    "    y = np.random.choice(n_classes, N)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X,y = make_data(N=2000, n_vars=50000)\n",
    "\n",
    "select = SelectKBest(f_regression, k=100)\n",
    "X_sel = select.fit_transform(X, y)\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "scores = cross_val_score(clf, X_sel, y, cv=5, n_jobs=8)\n",
    "\n",
    "print(\"Scores on each subset:\")\n",
    "print(scores)\n",
    "avg = (100*np.mean(scores), 100*np.std(scores)/np.sqrt(scores.shape[0]))\n",
    "print(\"Average score and uncertainty: (%.2f +- %.3f)%%\" % avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mistake that we are making here is that the \"test\" data used in the cross-validation is not independant of the training data because it has been used to compute the transformation and selection (i.e., it has been 'selected' already). To prevent this, one should separate the testing data and the training data from the beginning, and not use the testing data in the selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:\n",
      "0.511666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "np.random.seed(6450345)\n",
    "\n",
    "def make_data(N=1000, n_vars=10,\n",
    "              n_classes=2):\n",
    "    X = np.random.normal(size=(N,n_vars))\n",
    "    y = np.random.choice(n_classes, N)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X,y = make_data(N=2000, n_vars=50000)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)\n",
    "\n",
    "select = SelectKBest(f_regression, k=100)\n",
    "X_sel = select.fit_transform(X_train, y_train)\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_sel, y_train)\n",
    "#scores = cross_val_score(clf, X_sel, y_train, cv=5, n_jobs=8)\n",
    "\n",
    "X_sel_test = select.transform(X_test)\n",
    "score = clf.score(X_sel_test, y_test)\n",
    "\n",
    "print(\"Score:\")\n",
    "print(score)\n",
    "#avg = (100*np.mean(scores), 100*np.std(scores)/np.sqrt(scores.shape[0]))\n",
    "#print(\"Average score and uncertainty: (%.2f +- %.3f)%%\" % avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, we recover an accuracy close to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
